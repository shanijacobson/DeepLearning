# -*- coding: utf-8 -*-
"""Project-Ron.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qeimhBS15XylGgYO_7BkepB_Rqy6lFcy
"""

# Commented out IPython magic to ensure Python compatibility.
from tokenize import Double
import torch
import os
import sys
import numpy as np
from torch.utils.data import DataLoader, random_split

from Models.STLModel import SLTEfeaturesModel

DEVICE = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
#DEVICE = torch.device("cpu")


#os.chdir(r"C:\Users\Ron\Desktop\DeepLearning\Project")
DATA_PATH = os.path.join("Data", "Phoenix14")
emotions_val= os.path.join("Data", "Phoenix14","emothins.pkl")
emotions_train= os.path.join("Data", "Phoenix14","emothins_train.pkl")
poses_val= os.path.join("Data", "Phoenix14","poses_val.pkl")
poses_train= os.path.join("Data", "Phoenix14","poses_train.pkl")
SAVED_MODELS_PATH = "Data/models"
VALIDATION_SIZE = 520
BATCH_SIZE = 32
MINIMUM_LR = 1.0e-07
MAXIMUM_ITER = 5_000_000
SEED = 42

torch.manual_seed(SEED)

# %cd gdrive/MyDrive/DeepLearing/Project
import Models
# %cd /content

"""## **Initialization**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd gdrive/MyDrive/DeepLearing/Project

"""## **Load Data**"""

# Commented out IPython magic to ensure Python compatibility.
from Models import Vocabulary, FeatureModelLoss
from Models import SignGlossLanguage

# %cd gdrive/MyDrive/DeepLearing/Project

# Build Vocabularies:
gloss_vocab = Vocabulary.GlossVocabulary(DATA_PATH)
word_vocab = Vocabulary.WordVocabulary(DATA_PATH)

# Build Datasets

train_dataset = SignGlossLanguage(root=DATA_PATH, type="train", download=False,
                                  word_vocab=word_vocab, gloss_vocab=gloss_vocab, feature_path = poses_train,poses_flag=True)
valid_dataset = SignGlossLanguage(root=DATA_PATH, type="dev", download=False,
                                  word_vocab=word_vocab, gloss_vocab=gloss_vocab,feature_path = poses_val,poses_flag=True)
test_dataset = SignGlossLanguage(root=DATA_PATH, type="test", download=False,
                                 word_vocab=word_vocab, gloss_vocab=gloss_vocab)

train_loader = DataLoader(train_dataset, BATCH_SIZE, shuffle=True)
validation_loader = DataLoader(valid_dataset, BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, BATCH_SIZE, shuffle=False)

"""## **Training**"""
from Models import SLTModel, SLTModelLoss, Helper, Predictions
from torch.optim import Adam, lr_scheduler
from torch.utils.data.dataloader import T
from torchtext.data.metrics import bleu_score
from torchmetrics.functional import word_error_rate
from torch.utils.tensorboard import SummaryWriter

def calculate_validation_scores(beam_size=None, alpha=0, test=False, iter=0):
    model.eval()
    idx_to_words = word_vocab.get_itos()
    idx_to_glosses = gloss_vocab.get_itos()
    seq_to_words = {}
    total_loss = 0
    total_recognition_loss = 0
    total_translation_loss = 0
    total_features_loss = 0
    temp_device = torch.device("cpu")

    with torch.no_grad():
        txt_ref = []
        txt_hyp = []
        gls_ref = []
        gls_hyp = []
        data_loader = test_loader if test else validation_loader
        for batch in data_loader:
            (frames, frames_len), (glosses, glosses_len), (words, words_len) , features = batch
            (frames, glosses, words, features) = (frames.to(DEVICE), glosses.to(DEVICE), words.to(DEVICE), features.to(DEVICE))
            if type(model) == SLTEfeaturesModel:
                words_output, glosses_prob_output, encoder_output, features_prob_output , merge_output = model(frames, words)
                loss, recognition_loss, translation_loss, features_loss =  criterion(glosses, words, glosses_prob_output, words_output, frames_len, glosses_len,features,features_prob_output)
                total_features_loss += features_loss
                predict_words_list = Predictions.predict_words(model, frames, words, merge_output, word_vocab, beam_size, alpha)
                txt_hyp.extend(predict_words_list)

            else:
                words_output, glosses_prob_output, encoder_output = model(frames, words)
                loss, recognition_loss, translation_loss =  criterion(glosses, words, glosses_prob_output, words_output, frames_len, glosses_len)
                predict_words_list = Predictions.predict_words(model, frames, words, encoder_output, word_vocab, beam_size, alpha)
                txt_hyp.extend(predict_words_list)
            total_loss += loss
            total_recognition_loss += recognition_loss
            total_translation_loss += translation_loss


            # predict words and glosses
            real_words_list = [[[idx_to_words[seq[i+1]] for i in range(30) if seq[i+1] != word_vocab[Vocabulary.PAD_TOKEN]]] 
                                for seq in words]
            txt_ref.extend(real_words_list)
            real_gloss_list = [Predictions.clean_gloss_output([idx_to_glosses[seq[i+1]] for i in range(glosses.shape[1] - 1) if seq[i+1] != gloss_vocab[Vocabulary.PAD_TOKEN]]) 
                                for seq in glosses]                    
            gls_ref.extend(real_gloss_list)
            #predict_words_list = Predictions.predict_words(model, frames, words, encoder_output, word_vocab, beam_size, alpha)
           # txt_hyp.extend(predict_words_list)
            predict_glosses_list = Predictions.predict_glosses(idx_to_glosses, glosses_prob_output, frames_len, beam_size=1)
            gls_hyp.extend(predict_glosses_list)
            #print(real_words_list[0][0])
            #print(predict_words_list[0])


    validation_bleu_score = bleu_score(txt_hyp, txt_ref, max_n=4)
    validation_wer_score = word_error_rate(gls_hyp, gls_ref)
    #total_loss /= VALIDATION_SIZE
    #total_recognition_loss /= VALIDATION_SIZE
    #total_translation_loss /= VALIDATION_SIZE

    if type(model) == SLTEfeaturesModel:
     #   total_emo_loss /= VALIDATION_SIZE
        print(f"total_features_loss : {total_features_loss * criterion.feature_loss_weight },total_recognition_loss : {total_recognition_loss * criterion.gloss_loss_weight},total_translation_loss : {total_translation_loss * criterion.word_loss_weight}" )
    else:

        print(f"total_recognition_loss : {total_recognition_loss * criterion.gloss_loss_weight},total_translation_loss : {total_translation_loss * criterion.word_loss_weight}" )

    if not test:
        writer.add_scalar("total_loss/validation", total_loss, iter)
        writer.add_scalar("recognition_loss/validation", total_recognition_loss, iter) 
        writer.add_scalar("translation_loss/validation", total_translation_loss, iter)       
        writer.add_scalar('bleu/validation', validation_bleu_score, iter) 
        writer.add_scalar('wer/validation', validation_wer_score, iter) 
    return total_loss, validation_bleu_score, validation_wer_score


def train_on_batch(batch, iter):
    model.train()
    (frames, frames_len), (glosses, glosses_len), (words, words_len), features = batch
    (frames, glosses, words, features) = (frames.to(DEVICE), glosses.to(DEVICE), words.to(DEVICE), features.to(DEVICE))
    
    if type(model) == SLTEfeaturesModel:
        words_output, glosses_prob_output, _, features_prob_output ,_= model(frames, words)
        total_loss, recognition_loss, translation_loss, _ =  criterion(glosses, words, glosses_prob_output, words_output, frames_len, glosses_len,features,features_prob_output)

    else:
        words_output, glosses_prob_output, _ = model(frames, words)
        total_loss, recognition_loss, translation_loss =  criterion(glosses, words, glosses_prob_output, words_output, frames_len, glosses_len)
    
    optimizer.zero_grad()
    total_loss.backward()
    optimizer.step()
    writer.add_scalar("total_loss/train", total_loss / frames.shape[0], iter)
    writer.add_scalar("recognition_loss/train", recognition_loss / frames.shape[0], iter) 
    writer.add_scalar("translation_loss/train", translation_loss / frames.shape[0], iter) 
    return total_loss


def init_running_state(model_name):
    iter = 0
    best_lr = optimizer.param_groups[0]["lr"]
    best_bleu_score = -np.inf
    best_validation_loss = np.inf
    best_wer_score = np.inf
 #   state = Helper.restore_iteration_state(model_name)
 #   if state is not None:   
#        model.load_state_dict(state["model"])
#        optimizer.load_state_dict(state["optimizer"])
 #       scheduler.load_state_dict(state["scheduler"])
  #      iter = state["iteration"]
   #     best_lr = state["best_learning_rate"]
    #    best_bleu_score = state["best_bleu_score"]
     #   best_wer_score = state["best_wer_score"]
      #  best_validation_loss = state["best_validation_loss"]
    return iter, best_lr, best_bleu_score, best_wer_score, best_validation_loss


def fit(model_name):
    iter, best_lr, best_bleu_score, best_wer_score, best_validation_loss = init_running_state(model_name)
    
    stop = False
    epoch = 0
    
    while not stop:
        epoch_loss = 0
        for batch in train_loader:
            if (iter) % 100 == 0:

                validation_loss, validation_bleu_score, validation_wer_score = calculate_validation_scores(iter=iter)
                prev_lr = optimizer.param_groups[0]["lr"]
                scheduler.step(validation_bleu_score) 
                new_lr = optimizer.param_groups[0]["lr"]
                if type(model) == SLTEfeaturesModel:
                    if criterion.feature_train == 0:
                        optimizer.param_groups[0]["lr"] = 0.001
                        criterion.feature_train = -1
                    if criterion.gloss_train == 0:
                        optimizer.param_groups[0]["lr"] = 0.001
                        criterion.gloss_train = -1
                    if criterion.decoder_train == 0:
                        optimizer.param_groups[0]["lr"] = 0.001
                        criterion.decoder_train = -1
                if validation_bleu_score > best_bleu_score:
                    print(f"new best validation bleu score! validation loss: {validation_loss}, bleu score: {validation_bleu_score}, wer score: {validation_wer_score}")
                    best_bleu_score = validation_bleu_score
                   # torch.save(model.state_dict(), f"{SAVED_MODELS_PATH}/{model_name}/best_bleu_score_model_state")
                    best_lr = new_lr
                if validation_loss < best_validation_loss:
                    best_validation_loss = validation_loss
                   # torch.save(model.state_dict(), f"{SAVED_MODELS_PATH}/{model_name}/best_loss_model_state")
                if validation_wer_score < best_wer_score :
                    best_wer_score = validation_wer_score
                    print(f"new best validation wer score! validation loss: {validation_loss}, bleu score: {validation_bleu_score}, wer score: {validation_wer_score}")
                   # torch.save(model.state_dict(), f"{SAVED_MODELS_PATH}/{model_name}/best_wer_score_model_state")
                if prev_lr != new_lr:
                    print(f"new lr: {new_lr}")
                    if  best_bleu_score > 0.12 and best_lr != prev_lr:
                        stop = True
            print(f"bleu score: {validation_bleu_score}, wer score: {validation_wer_score}")

            print(f"Epoch: {epoch}, Train loss: {epoch_loss }, Validation loss: {validation_loss}")

            epoch_loss += train_on_batch(batch, iter)
           # if optimizer.param_groups[0]["lr"] < MINIMUM_LR or iter > 100:
         #       stop = True
          #      break
            iter += 1
        if (epoch) % 20:
            Helper.save_running_state(model_name,
                                      iteration=iter,
                                      best_learning_rate=best_lr,
                                      best_bleu_score=best_bleu_score,
                                      best_wer_score=best_wer_score,
                                      best_validation_loss=best_validation_loss,
                                      model_state_dict=model.state_dict(),
                                      optimizer_state_dict=optimizer.state_dict(),
                                      scheduler_state_dict=scheduler.state_dict())
        epoch += 1


model = SLTEfeaturesModel(frame_size=1024, gloss_dim=len(gloss_vocab), words_dim=len(word_vocab),
                num_layers_encoder=3, num_layers_decoder=3,num_layers_features=2,features_dim=99,dropout_decoder = 0.3,dropout_encoder = 0.2,
                word_padding_idx=word_vocab[Vocabulary.PAD_TOKEN], poses_flag=True).to(DEVICE)

# model = SLTModel(frame_size=1024, gloss_dim=len(gloss_vocab), words_dim=len(word_vocab),
#                 num_layers_encoder=3, num_layers_decoder=3,dropout_decoder = 0.3,
#                 word_padding_idx=word_vocab[Vocabulary.PAD_TOKEN]).to(DEVICE)

optimizer = Adam(model.parameters(), lr=0.001, 
                weight_decay=0.001, eps=1.0e-8, amsgrad=False)
scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode="max", threshold_mode="abs", 
                                            verbose=False, factor=0.7, patience=8)
criterion = FeatureModelLoss(gloss_vocab=gloss_vocab,
                            gloss_loss_weight = 5, word_loss_weight = 1, feature_loss_weight=0.01,
                            word_ignore_index=word_vocab[Vocabulary.PAD_TOKEN],feature_train=1000,gloss_train=0,decoder_train=0,poses_flag= True).to(DEVICE)

# criterion = SLTModelLoss(gloss_vocab=gloss_vocab,
#                              gloss_loss_weight = 5, word_loss_weight = 1,
#                              word_ignore_index=word_vocab[Vocabulary.PAD_TOKEN]).to(DEVICE)
                             
writer = SummaryWriter(log_dir = f"runs/test")                     
#calculate_validation_scores(1)
fit("test")
writer.flush()#fit()

